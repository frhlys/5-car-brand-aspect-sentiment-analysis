{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14fa3826-83bd-4cd2-91d9-3c658ac7ba08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\farah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8597c39-4964-4d60-a247-27fe8ec4a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries regarding topic modelling\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae2844ea-29c7-4483-a743-8629ef6c2576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  Rating  car_year brand_name        date  \\\n",
      "0             0           0     5.0      2018       Audi  2018-07-11   \n",
      "1             1           1     5.0      2018       Audi  2018-06-24   \n",
      "2             2           2     5.0      2018       Audi  2018-05-02   \n",
      "3             3           3     5.0      2018       Audi  2017-12-07   \n",
      "4             4           4     5.0      2018       Audi  2017-10-25   \n",
      "\n",
      "                                              review  \\\n",
      "0  BEST ALL AROUND PURPOSE CROSSOVER SUV I have n...   \n",
      "1  Best car This is a wonderful car.  The technol...   \n",
      "2                        Great Buy Do your home work   \n",
      "3  Fun Car Great ride. Loaded with technology. St...   \n",
      "4  Best luxury SUV w/ perfect comfort/sport balan...   \n",
      "\n",
      "                                     sentiment score relative sentiments  \\\n",
      "0  {'neg': 0.026, 'neu': 0.815, 'pos': 0.16, 'com...            positive   \n",
      "1  {'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'comp...            positive   \n",
      "2  {'neg': 0.0, 'neu': 0.549, 'pos': 0.451, 'comp...            positive   \n",
      "3  {'neg': 0.0, 'neu': 0.598, 'pos': 0.402, 'comp...            positive   \n",
      "4  {'neg': 0.02, 'neu': 0.811, 'pos': 0.169, 'com...            positive   \n",
      "\n",
      "                                      review_cleaned  \n",
      "0  ['around', 'purpose', 'crossover', 'seen', 'dr...  \n",
      "1  ['best', 'wonderful', 'technology', 'adaptable...  \n",
      "2                                            ['buy']  \n",
      "3  ['fun', 'ride', 'loaded', 'technology', 'steer...  \n",
      "4  ['best', 'luxury', 'w/', 'perfect', 'comfort/s...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the aspect sentiment data (make sure the path is correct)\n",
    "df_car = pd.read_csv('data_sentiment_pp_balanced.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to check the data\n",
    "print(df_car.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d171fb5-8dbd-4caf-8c0f-aa0707c73024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car.drop('Unnamed: 0.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22541d05-8f1c-4b65-a88f-75c7dc20770f",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16b5e38b-3f5b-4f37-a5af-5c113571c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = []\n",
    "for i in range(len(df_car['review_cleaned'])):\n",
    "    big_array.extend(df_car['review_cleaned'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1b8680-a88f-4eb4-970d-1e60c5a284db",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = [' '.join(big_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3740344e-9e5e-4778-aa5c-572e4f24b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_sent1 =[ i for i in docs1 ]\n",
    "docs = lng_sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cd418-5485-4513-ae38-34e47ca9e5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5bc270-1bf6-457e-8807-617c9da7d8ad",
   "metadata": {},
   "source": [
    "# Biigram ( Collocations With 2 words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5550af9-4cd9-4b6f-adf6-24e84d6b8e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', \"'\", 'a', 'r', 'o', 'u', 'n', 'd', \"'\", ',']\n"
     ]
    }
   ],
   "source": [
    "print(big_array[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c730d0-8fe9-439a-bcd8-7568bb8ac2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57320a17-df3a-4698-b5a5-8dbe74ccc513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d47dff89-8560-4ec4-8e2d-14ca5e8cc4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', ' '),\n",
       " (' ', \"'\"),\n",
       " (\"'\", ','),\n",
       " (']', '['),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('i', \"'\"),\n",
       " ('e', ','),\n",
       " (\"'\", 'e'),\n",
       " ('a', \"'\"),\n",
       " ('e', 'd'),\n",
       " ('e', 'r'),\n",
       " ('v', 'e'),\n",
       " ('y', \"'\"),\n",
       " ('l', 'e')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import webtext\n",
    "  \n",
    "# use to find bigrams, which are pairs of words\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "biagram_collocation = BigramCollocationFinder.from_words(big_array)\n",
    "biagram_collocation.apply_freq_filter(3)\n",
    "bigram_list = biagram_collocation.nbest(BigramAssocMeasures.likelihood_ratio, 15)\n",
    "\n",
    "bigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26a87d8c-0e0c-4546-8356-6826f091cf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', ' '), 1106279),\n",
       " ((' ', \"'\"), 1086122),\n",
       " ((\"'\", ','), 1085768),\n",
       " (('e', \"'\"), 214833),\n",
       " (('t', \"'\"), 138160),\n",
       " (('i', 'n'), 137304),\n",
       " ((\"'\", 's'), 137165),\n",
       " (('d', \"'\"), 127888),\n",
       " (('e', 'r'), 124382),\n",
       " (('r', \"'\"), 95824),\n",
       " (('n', 'g'), 93463),\n",
       " ((\"'\", 'c'), 89447),\n",
       " (('g', \"'\"), 88892),\n",
       " (('l', 'e'), 86432),\n",
       " (('r', 'e'), 85650),\n",
       " (('e', 'd'), 84251),\n",
       " (('y', \"'\"), 77202),\n",
       " ((\"'\", 'p'), 76421),\n",
       " ((\"'\", 'm'), 70445),\n",
       " (('e', 'a'), 70010),\n",
       " (('o', 'n'), 70000),\n",
       " (('s', 't'), 69066),\n",
       " (('t', 'e'), 68809),\n",
       " ((\"'\", 'r'), 68058),\n",
       " ((\"'\", 't'), 65100),\n",
       " (('r', 'i'), 65052),\n",
       " (('n', \"'\"), 63837),\n",
       " (('a', 'n'), 63772),\n",
       " (('e', 'n'), 63750),\n",
       " (('n', 't'), 62961),\n",
       " ((\"'\", 'l'), 62018),\n",
       " ((\"'\", 'b'), 60859),\n",
       " ((\"'\", 'd'), 60858),\n",
       " (('t', 'i'), 60685),\n",
       " ((\"'\", 'f'), 60355),\n",
       " (('o', 'r'), 60097),\n",
       " (('s', 'e'), 57827),\n",
       " (('l', \"'\"), 57156),\n",
       " (('a', 'r'), 56202),\n",
       " (('d', 'e'), 53060),\n",
       " (('v', 'e'), 52216),\n",
       " (('a', 't'), 50404),\n",
       " (('c', 'o'), 49973),\n",
       " ((\"'\", 'a'), 49247),\n",
       " (('n', 'e'), 48800),\n",
       " ((\"'\", 'e'), 47864),\n",
       " (('c', 'e'), 47854),\n",
       " (('r', 'a'), 46329),\n",
       " (('s', \"'\"), 45987),\n",
       " (('l', 'i'), 45880),\n",
       " (('a', 'l'), 45129),\n",
       " ((\"'\", 'g'), 44815),\n",
       " ((\"'\", 'w'), 41760),\n",
       " (('e', 'l'), 41681),\n",
       " (('r', 'o'), 41553),\n",
       " (('e', 's'), 40462),\n",
       " (('p', 'e'), 39691),\n",
       " (('m', 'a'), 39393),\n",
       " ((\"'\", 'h'), 39215),\n",
       " (('n', 'd'), 38701),\n",
       " (('i', 'o'), 38314),\n",
       " (('a', 's'), 38182),\n",
       " (('g', 'e'), 36887),\n",
       " (('o', 'm'), 35608),\n",
       " (('e', 'e'), 35473),\n",
       " (('i', 't'), 34151),\n",
       " (('e', 't'), 33801),\n",
       " (('i', 'c'), 33453),\n",
       " (('m', 'e'), 33401),\n",
       " (('l', 'o'), 32606),\n",
       " (('l', 'a'), 32276),\n",
       " ((']', '['), 31937),\n",
       " (('a', 'c'), 31768),\n",
       " ((\"'\", ']'), 31713),\n",
       " (('t', 'h'), 31409),\n",
       " (('[', \"'\"), 31325),\n",
       " (('s', 'i'), 31285),\n",
       " (('o', 'w'), 31223),\n",
       " (('u', 'r'), 30745),\n",
       " (('h', 'i'), 29824),\n",
       " (('k', \"'\"), 29536),\n",
       " (('c', 'h'), 29431),\n",
       " (('t', 'r'), 29397),\n",
       " (('h', 'a'), 29211),\n",
       " ((\"'\", 'o'), 29171),\n",
       " (('b', 'l'), 28620),\n",
       " (('i', 's'), 28522),\n",
       " (('o', 'o'), 28132),\n",
       " (('t', 'a'), 28063),\n",
       " ((\"'\", 'i'), 27957),\n",
       " (('h', \"'\"), 27875),\n",
       " (('i', 'v'), 27421),\n",
       " (('u', 'n'), 26866),\n",
       " (('p', 'r'), 26028),\n",
       " (('i', 'l'), 25398),\n",
       " (('e', 'c'), 25388),\n",
       " (('o', 'u'), 25326),\n",
       " ((\"'\", 'n'), 25174),\n",
       " (('r', 't'), 25083),\n",
       " (('t', 'o'), 24728),\n",
       " (('p', 'a'), 24206),\n",
       " (('a', 'd'), 24115),\n",
       " (('u', 's'), 23951),\n",
       " (('m', \"'\"), 23812),\n",
       " (('i', 'g'), 23697),\n",
       " (('i', 'd'), 23571),\n",
       " (('l', 'l'), 23486),\n",
       " (('s', 's'), 23484),\n",
       " (('m', 'i'), 23388),\n",
       " (('p', 'o'), 23362),\n",
       " (('h', 'e'), 23180),\n",
       " (('o', 't'), 23114),\n",
       " (('c', 'a'), 22973),\n",
       " (('a', 'i'), 22083),\n",
       " (('e', 'm'), 22078),\n",
       " (('d', 'r'), 21972),\n",
       " (('v', 'i'), 21861),\n",
       " (('t', 'y'), 21720),\n",
       " (('p', \"'\"), 21636),\n",
       " (('k', 'e'), 21428),\n",
       " (('m', 'o'), 21031),\n",
       " (('m', 'p'), 20911),\n",
       " (('d', 'i'), 20711),\n",
       " (('b', 'e'), 20578),\n",
       " (('\"', ','), 20538),\n",
       " (('\"', \"'\"), 20529),\n",
       " (('f', 'o'), 20346),\n",
       " (('o', 'l'), 20297),\n",
       " (('f', 'i'), 20293),\n",
       " ((' ', '\"'), 20157),\n",
       " (('w', 'a'), 20093),\n",
       " (('n', 'c'), 20059),\n",
       " (('f', 'e'), 19786),\n",
       " (('i', 'r'), 19350),\n",
       " (('s', 'p'), 19261),\n",
       " (('c', 'k'), 19215),\n",
       " (('e', 'x'), 19029),\n",
       " (('n', 'o'), 18798),\n",
       " (('w', 'e'), 18679),\n",
       " (('t', 't'), 18513),\n",
       " (('p', 'l'), 18441),\n",
       " (('i', 'e'), 18430),\n",
       " (('s', 'h'), 17996),\n",
       " (('n', 's'), 17935),\n",
       " (('s', 'u'), 17881),\n",
       " (('a', 'b'), 17873),\n",
       " (('i', 'm'), 17853),\n",
       " (('a', 'y'), 17787),\n",
       " (('c', 't'), 17439),\n",
       " (('g', 'h'), 17424),\n",
       " (('s', 'o'), 17216),\n",
       " (('n', 'i'), 16897),\n",
       " (('f', 'u'), 16636),\n",
       " (('e', 'p'), 16410),\n",
       " ((\"'\", 'v'), 16368),\n",
       " ((\"'\", 'u'), 16303),\n",
       " (('a', 'g'), 15811),\n",
       " (('u', 't'), 15691),\n",
       " (('h', 'o'), 15557),\n",
       " (('r', 's'), 15430),\n",
       " (('r', 'y'), 14496),\n",
       " (('u', 'e'), 14474),\n",
       " (('w', \"'\"), 14470),\n",
       " (('g', 'o'), 14180),\n",
       " (('l', 'u'), 14160),\n",
       " (('s', 'a'), 13910),\n",
       " (('o', \"'\"), 13726),\n",
       " (('a', 'k'), 13707),\n",
       " (('q', 'u'), 13459),\n",
       " (('o', 'k'), 13438),\n",
       " (('o', 'p'), 13188),\n",
       " (('a', 'm'), 13166),\n",
       " (('u', 'l'), 13138),\n",
       " (('b', 'u'), 13105),\n",
       " (('o', 'v'), 12536),\n",
       " (('d', 'a'), 12365),\n",
       " (('n', 'a'), 12255),\n",
       " (('e', 'v'), 12023),\n",
       " (('t', 'u'), 11980),\n",
       " ((\"'\", 'q'), 11917),\n",
       " (('o', 'i'), 11618),\n",
       " (('p', 'u'), 11437),\n",
       " (('w', 'n'), 11214),\n",
       " (('r', 'm'), 11122),\n",
       " (('g', 'i'), 11024),\n",
       " (('c', 'l'), 11020),\n",
       " (('r', 'f'), 10799),\n",
       " (('f', 'a'), 10784),\n",
       " (('c', \"'\"), 10741),\n",
       " (('b', 'i'), 10702),\n",
       " (('a', 'p'), 10411),\n",
       " (('g', 'a'), 10394),\n",
       " (('k', 'i'), 10290),\n",
       " (('u', 'i'), 10172),\n",
       " (('b', 'a'), 10132),\n",
       " (('h', 't'), 10032),\n",
       " (('i', 'f'), 9951),\n",
       " (('s', 'm'), 9947),\n",
       " (('a', 'v'), 9912),\n",
       " (('l', 'd'), 9857),\n",
       " (('u', 'p'), 9724),\n",
       " (('o', 'd'), 9703),\n",
       " (('o', 'b'), 9644),\n",
       " (('o', 's'), 9606),\n",
       " (('p', 'p'), 9594),\n",
       " ((\"'\", 'k'), 9371),\n",
       " (('s', '\"'), 9260),\n",
       " (('d', 'l'), 9208),\n",
       " (('b', 'r'), 9131),\n",
       " (('i', 'p'), 9012),\n",
       " (('r', 'u'), 8971),\n",
       " (('i', 'a'), 8812),\n",
       " (('a', 'u'), 8718),\n",
       " (('u', 'a'), 8708),\n",
       " (('y', 'e'), 8369),\n",
       " (('0', \"'\"), 8310),\n",
       " (('w', 'i'), 8252),\n",
       " (('r', 'n'), 8185),\n",
       " (('d', 'o'), 8071),\n",
       " (('r', 'd'), 8061),\n",
       " (('r', 'r'), 7940),\n",
       " (('a', \"'\"), 7892),\n",
       " (('w', 'o'), 7883),\n",
       " (('m', 'f'), 7799),\n",
       " (('u', 'm'), 7654),\n",
       " (('s', 'y'), 7591),\n",
       " (('c', 'i'), 7376),\n",
       " (('x', 'p'), 7309),\n",
       " (('r', 'c'), 7113),\n",
       " (('c', 'r'), 7069),\n",
       " ((\"'\", 'y'), 7049),\n",
       " (('b', 'o'), 7030),\n",
       " (('f', 'f'), 6897),\n",
       " (('e', '\"'), 6827),\n",
       " (('n', 'y'), 6770),\n",
       " (('l', 't'), 6648),\n",
       " (('g', 'r'), 6638),\n",
       " (('c', 'u'), 6502),\n",
       " (('t', 'l'), 6304),\n",
       " (('p', 'i'), 6296),\n",
       " (('u', 'c'), 6294),\n",
       " (('u', 'y'), 6223),\n",
       " (('f', 'r'), 6081),\n",
       " (('.', '.'), 6002),\n",
       " (('v', 'a'), 5988),\n",
       " (('u', 'g'), 5898),\n",
       " (('x', \"'\"), 5835),\n",
       " (('m', 'b'), 5525),\n",
       " (('m', 'm'), 5435),\n",
       " (('b', \"'\"), 5424),\n",
       " (('y', 's'), 5385),\n",
       " (('o', 'c'), 5368),\n",
       " (('r', 'k'), 5351),\n",
       " (('c', 'c'), 5341),\n",
       " (('a', 'w'), 5333),\n",
       " (('5', \"'\"), 5308),\n",
       " (('x', 'c'), 5271),\n",
       " (('u', 'x'), 5252),\n",
       " (('p', 't'), 5231),\n",
       " (('l', 'y'), 5170),\n",
       " (('w', 'h'), 5164),\n",
       " (('x', 'u'), 5155),\n",
       " (('m', 'u'), 5112),\n",
       " (('e', 'w'), 5062),\n",
       " (('e', 'g'), 4874),\n",
       " (('f', 't'), 4794),\n",
       " (('t', 's'), 4791),\n",
       " (('r', 'v'), 4684),\n",
       " ((\"'\", 'j'), 4572),\n",
       " (('a', 'f'), 4536),\n",
       " (('e', 'f'), 4478),\n",
       " (('r', 'g'), 4454),\n",
       " (('o', 'a'), 4384),\n",
       " (('s', 'c'), 4369),\n",
       " (('j', 'o'), 4344),\n",
       " (('p', 'g'), 4337),\n",
       " (('g', 'n'), 4250),\n",
       " (('o', 'f'), 4218),\n",
       " (('x', 't'), 4116),\n",
       " (('e', 'y'), 4054),\n",
       " (('n', 'u'), 4003),\n",
       " (('f', \"'\"), 3983),\n",
       " (('i', \"'\"), 3963),\n",
       " (('o', 'y'), 3930),\n",
       " (('y', 'l'), 3901),\n",
       " (('d', 'u'), 3887),\n",
       " (('n', 'n'), 3873),\n",
       " (('f', 'l'), 3863),\n",
       " (('s', 'l'), 3755),\n",
       " (('i', 'b'), 3740),\n",
       " (('y', 't'), 3654),\n",
       " (('n', 'k'), 3633),\n",
       " (('t', 'c'), 3632),\n",
       " ((\"'\", 'x'), 3499),\n",
       " (('5', '0'), 3488),\n",
       " (('m', '\"'), 3411),\n",
       " (('g', 'l'), 3390),\n",
       " (('u', 'd'), 3376),\n",
       " (('3', '5'), 3366),\n",
       " (('p', 'h'), 3344),\n",
       " (('k', 'n'), 3323),\n",
       " (('k', 'a'), 3320),\n",
       " (('g', 'u'), 3282),\n",
       " (('y', 'i'), 3260),\n",
       " (('4', \"'\"), 3241),\n",
       " (('r', 'b'), 3224),\n",
       " (('d', 'd'), 3011),\n",
       " (('3', \"'\"), 3008),\n",
       " (('.', \"'\"), 2984),\n",
       " (('h', 'w'), 2969),\n",
       " (('a', 'z'), 2950),\n",
       " (('0', '0'), 2938),\n",
       " (('z', 'e'), 2936),\n",
       " (('i', 'x'), 2816),\n",
       " (('d', 's'), 2671),\n",
       " (('o', 'g'), 2670),\n",
       " (('e', 'k'), 2667),\n",
       " (('6', \"'\"), 2638),\n",
       " (('d', 'y'), 2631),\n",
       " (('r', 'p'), 2628),\n",
       " ((\"'\", '.'), 2617),\n",
       " (('z', 'i'), 2465),\n",
       " (('3', '0'), 2464),\n",
       " (('i', 'z'), 2463),\n",
       " (('u', 'b'), 2437),\n",
       " (('l', 'k'), 2327),\n",
       " (('s', 'n'), 2308),\n",
       " (('m', 's'), 2296),\n",
       " (('l', 's'), 2250),\n",
       " (('y', 'o'), 2229),\n",
       " (('v', 'o'), 2210),\n",
       " (('g', 'g'), 2202),\n",
       " (('h', 'u'), 2182),\n",
       " (('.', 'i'), 2153),\n",
       " (('p', 'y'), 2150),\n",
       " (('n', 'j'), 2092),\n",
       " (('e', 'o'), 2013),\n",
       " (('i', 'u'), 1984),\n",
       " (('v', \"'\"), 1960),\n",
       " (('m', 'y'), 1957),\n",
       " (('e', 'q'), 1904),\n",
       " (('n', 'f'), 1879),\n",
       " (('j', 'u'), 1858),\n",
       " (('e', 'i'), 1850),\n",
       " (('.', 't'), 1837),\n",
       " (('e', '-'), 1782),\n",
       " (('r', 'x'), 1776),\n",
       " (('t', 'm'), 1738),\n",
       " (('n', 'v'), 1692),\n",
       " (('-', \"'\"), 1687),\n",
       " (('g', 's'), 1673),\n",
       " (('x', '5'), 1649),\n",
       " (('-', 's'), 1639),\n",
       " (('x', '3'), 1634),\n",
       " (('x', 'e'), 1630),\n",
       " (('s', 'w'), 1627),\n",
       " (('e', '.'), 1624),\n",
       " (('h', 'r'), 1623),\n",
       " (('r', 'l'), 1600),\n",
       " (('s', 'k'), 1573),\n",
       " (('8', \"'\"), 1543),\n",
       " (('a', '4'), 1543),\n",
       " (('s', '.'), 1530),\n",
       " (('w', 'd'), 1518),\n",
       " (('2', '0'), 1517),\n",
       " (('w', 'r'), 1469),\n",
       " (('h', 'n'), 1450),\n",
       " (('e', 'h'), 1381),\n",
       " (('m', '3'), 1379),\n",
       " (('c', 'y'), 1374),\n",
       " (('k', 's'), 1358),\n",
       " (('h', 'y'), 1356),\n",
       " ((\"'\", 'z'), 1347),\n",
       " (('g', '3'), 1334),\n",
       " (('m', 'l'), 1258),\n",
       " (('s', '4'), 1245),\n",
       " (('g', 'y'), 1224),\n",
       " (('j', 'a'), 1210),\n",
       " (('i', 'k'), 1179),\n",
       " (('l', 'v'), 1135),\n",
       " ((\"'\", '’'), 1125),\n",
       " (('’', \"'\"), 1125),\n",
       " (('u', 'f'), 1115),\n",
       " (('t', 'w'), 1114),\n",
       " (('b', 's'), 1093),\n",
       " (('n', 'r'), 1085),\n",
       " (('n', '-'), 1079),\n",
       " (('p', 's'), 1063),\n",
       " (('7', \"'\"), 1060),\n",
       " (('d', 'v'), 1052),\n",
       " (('l', 'f'), 1045),\n",
       " (('a', '6'), 1042),\n",
       " (('p', 'd'), 1035),\n",
       " (('l', 'p'), 1029),\n",
       " (('x', 'i'), 1027),\n",
       " (('t', '.'), 1022),\n",
       " (('d', 'g'), 995),\n",
       " (('a', 'j'), 986),\n",
       " (('-', 'c'), 986),\n",
       " (('w', 's'), 984),\n",
       " (('k', 'y'), 982),\n",
       " (('j', 'e'), 975),\n",
       " (('e', '3'), 973),\n",
       " (('v', 'y'), 958),\n",
       " (('s', '-'), 947),\n",
       " (('s', '3'), 942),\n",
       " (('m', 'g'), 922),\n",
       " (('s', 'f'), 919),\n",
       " (('r', '-'), 912),\n",
       " (('-', 't'), 905),\n",
       " (('r', 'q'), 899),\n",
       " (('o', 'x'), 898),\n",
       " (('r', '.'), 888),\n",
       " (('6', '0'), 880),\n",
       " (('f', 'x'), 845),\n",
       " ((\"'\", '0'), 844),\n",
       " (('0', '-'), 842),\n",
       " (('d', '-'), 840),\n",
       " (('c', 's'), 829),\n",
       " (('3', '2'), 828),\n",
       " (('u', 'v'), 821),\n",
       " (('c', 'd'), 819),\n",
       " (('b', 'm'), 815),\n",
       " ((\"'\", '2'), 814),\n",
       " (('4', '5'), 806),\n",
       " (('l', '-'), 790),\n",
       " (('q', '5'), 777),\n",
       " (('m', 'w'), 771),\n",
       " (('/', 'c'), 756),\n",
       " (('q', 'x'), 755),\n",
       " (('y', 'b'), 754),\n",
       " (('d', 'j'), 753),\n",
       " (('y', 'p'), 753),\n",
       " (('t', '-'), 752),\n",
       " (('h', 'p'), 743),\n",
       " (('w', '/'), 739),\n",
       " (('u', \"'\"), 733),\n",
       " (('-', 'd'), 728),\n",
       " (('5', '5'), 725),\n",
       " (('e', 'b'), 721),\n",
       " ((\"'\", '%'), 718),\n",
       " (('%', \"'\"), 718),\n",
       " (('s', 'q'), 706),\n",
       " (('e', 'u'), 695),\n",
       " (('a', 'x'), 692),\n",
       " (('x', 'h'), 686),\n",
       " (('v', '8'), 678),\n",
       " (('x', '4'), 675),\n",
       " (('-', 'l'), 671),\n",
       " (('-', 'o'), 669),\n",
       " (('n', 'l'), 663),\n",
       " (('/', \"'\"), 661),\n",
       " (('n', 'm'), 655),\n",
       " (('d', '.'), 647),\n",
       " (('2', \"'\"), 627),\n",
       " (('4', '3'), 627),\n",
       " ((\"'\", '1'), 619),\n",
       " (('p', 'm'), 610),\n",
       " (('-', '2'), 603),\n",
       " (('[', '\"'), 598),\n",
       " (('o', '-'), 590),\n",
       " (('y', 'a'), 588),\n",
       " (('x', '9'), 585),\n",
       " (('f', 'y'), 581),\n",
       " (('\\\\', 'x'), 579),\n",
       " (('.', 'a'), 578),\n",
       " (('-', 'b'), 576),\n",
       " (('s', '/'), 576),\n",
       " (('-', '3'), 576),\n",
       " (('-', 'f'), 575),\n",
       " (('4', '0'), 574),\n",
       " (('3', '7'), 569),\n",
       " (('s', '5'), 565),\n",
       " (('w', 'l'), 562),\n",
       " (('o', 'e'), 562),\n",
       " (('l', 'b'), 552),\n",
       " ((\"'\", '4'), 549),\n",
       " (('-', '6'), 543),\n",
       " ((\"'\", '3'), 542),\n",
       " (('r', 'w'), 535),\n",
       " (('g', 't'), 534),\n",
       " (('w', 'y'), 523),\n",
       " (('5', '-'), 517),\n",
       " (('h', 'l'), 507),\n",
       " (('v', '6'), 507),\n",
       " (('i', '-'), 504),\n",
       " (('e', '/'), 498),\n",
       " (('b', 't'), 497),\n",
       " (('l', '5'), 492),\n",
       " (('n', 'b'), 491),\n",
       " (('/', 's'), 490),\n",
       " (('y', '.'), 486),\n",
       " (('y', 'n'), 484),\n",
       " (('g', 'x'), 480),\n",
       " (('c', '3'), 480),\n",
       " (('b', 'b'), 477),\n",
       " (('c', '2'), 477),\n",
       " (('a', '8'), 469),\n",
       " (('h', 'b'), 469),\n",
       " (('n', '.'), 464),\n",
       " (('z', \"'\"), 463),\n",
       " (('-', 'r'), 462),\n",
       " (('1', \"'\"), 459),\n",
       " ((\"'\", '*'), 452),\n",
       " (('*', \"'\"), 452),\n",
       " ((\"'\", '5'), 445),\n",
       " (('-', 'w'), 445),\n",
       " (('q', '7'), 443),\n",
       " (('y', 'r'), 443),\n",
       " (('-', 'p'), 442),\n",
       " (('a', '/'), 442),\n",
       " (('7', '0'), 439),\n",
       " (('c', 'p'), 439),\n",
       " (('y', 'd'), 438),\n",
       " (('k', 'u'), 436),\n",
       " (('-', 'i'), 433),\n",
       " (('v', 's'), 427),\n",
       " (('2', '5'), 423),\n",
       " (('9', '2'), 423),\n",
       " (('z', '4'), 422),\n",
       " (('k', '-'), 420),\n",
       " (('3', '-'), 417),\n",
       " (('g', '.'), 415),\n",
       " (('4', '-'), 405),\n",
       " (('-', 'a'), 399),\n",
       " (('i', 'q'), 396),\n",
       " (('.', 'w'), 387),\n",
       " (('.', 's'), 387),\n",
       " (('-', '1'), 381),\n",
       " (('-', 'u'), 380),\n",
       " (('x', 'a'), 378),\n",
       " (('2', '3'), 378),\n",
       " (('y', 'm'), 377),\n",
       " (('i', '3'), 375),\n",
       " (('d', 'm'), 374),\n",
       " (('v', 'w'), 371),\n",
       " (('r', '/'), 371),\n",
       " (('y', '-'), 368),\n",
       " (('m', 'r'), 368),\n",
       " (('a', 'h'), 367),\n",
       " (('-', 'm'), 365),\n",
       " (('l', 'c'), 363),\n",
       " (('g', 'p'), 353),\n",
       " (('p', 'k'), 351),\n",
       " (('a', '3'), 350),\n",
       " (('6', '-'), 345),\n",
       " (('t', 'd'), 343),\n",
       " (('d', 'x'), 343),\n",
       " (('f', '-'), 343),\n",
       " (('x', 'y'), 338),\n",
       " (('-', 'e'), 337),\n",
       " (('a', 'a'), 337),\n",
       " (('l', 'x'), 337),\n",
       " (('y', '/'), 334),\n",
       " (('x', '-'), 334),\n",
       " (('l', '3'), 331),\n",
       " (('g', 'm'), 330),\n",
       " (('/', 't'), 330),\n",
       " (('z', 'z'), 329),\n",
       " (('m', '5'), 327),\n",
       " (('l', '.'), 326),\n",
       " (('+', \"'\"), 326),\n",
       " (('m', '-'), 325),\n",
       " ((\"'\", '6'), 324),\n",
       " (('k', 'g'), 318),\n",
       " (('.', 'm'), 317),\n",
       " (('b', 'y'), 315),\n",
       " (('n', '/'), 311),\n",
       " (('t', '/'), 307),\n",
       " (('8', '0'), 303),\n",
       " ((\"'\", '/'), 303),\n",
       " ((\"'\", '-'), 302),\n",
       " (('z', 'y'), 299),\n",
       " (('m', 'd'), 298),\n",
       " (('.', 'c'), 298),\n",
       " (('l', 'm'), 289),\n",
       " (('.', 'b'), 288),\n",
       " (('c', 'v'), 288),\n",
       " (('h', 's'), 279),\n",
       " (('t', 'b'), 277),\n",
       " (('p', '-'), 277),\n",
       " (('h', '-'), 274),\n",
       " (('d', '/'), 273),\n",
       " (('1', '0'), 272),\n",
       " (('z', 'a'), 272),\n",
       " (('v', '-'), 272),\n",
       " (('n', 'h'), 271),\n",
       " (('.', 'o'), 270),\n",
       " (('-', '4'), 269),\n",
       " (('2', '-'), 268),\n",
       " (('-', '8'), 268),\n",
       " (('k', 'o'), 264),\n",
       " (('v', 'd'), 264),\n",
       " (('n', 'p'), 263),\n",
       " (('m', '4'), 261),\n",
       " (('s', 'r'), 261),\n",
       " (('s', '6'), 253),\n",
       " (('/', 'h'), 253),\n",
       " (('n', 'x'), 253),\n",
       " (('x', '6'), 253),\n",
       " (('k', 'l'), 250),\n",
       " (('.', 'n'), 246),\n",
       " (('d', 'n'), 246),\n",
       " (('g', '-'), 245),\n",
       " (('-', '5'), 242),\n",
       " (('t', 'p'), 240),\n",
       " ((\"'\", '+'), 240),\n",
       " (('s', 'b'), 239),\n",
       " (('e', 'z'), 239),\n",
       " ((\"'\", '7'), 238),\n",
       " (('o', 'h'), 238),\n",
       " (('v', 't'), 238),\n",
       " (('5', '6'), 238),\n",
       " (('q', '4'), 236),\n",
       " (('.', 'e'), 234),\n",
       " (('/', 'a'), 234),\n",
       " (('w', '-'), 232),\n",
       " (('2', '8'), 232),\n",
       " (('t', 'f'), 231),\n",
       " (('t', 'n'), 231),\n",
       " (('k', 'm'), 231),\n",
       " ((\"'\", '@'), 230),\n",
       " (('@', \"'\"), 230),\n",
       " (('.', 'h'), 229),\n",
       " (('z', '3'), 228),\n",
       " (('l', 'n'), 227),\n",
       " (('/', 'r'), 227),\n",
       " (('a', '5'), 226),\n",
       " (('c', '-'), 224),\n",
       " (('.', 'g'), 224),\n",
       " (('e', '5'), 223),\n",
       " (('2', '4'), 223),\n",
       " (('e', '4'), 221),\n",
       " (('c', '4'), 220),\n",
       " ((\"'\", '9'), 218),\n",
       " (('4', '6'), 218),\n",
       " (('\"', ']'), 217),\n",
       " (('s', '2'), 215),\n",
       " (('c', '.'), 214),\n",
       " (('7', '-'), 214),\n",
       " (('s', 'g'), 211),\n",
       " (('w', 'f'), 211),\n",
       " (('d', 'b'), 211),\n",
       " (('4', '7'), 211),\n",
       " (('x', '1'), 210),\n",
       " (('u', 'z'), 209),\n",
       " (('q', \"'\"), 209),\n",
       " (('a', '-'), 209),\n",
       " (('y', 'c'), 208),\n",
       " (('m', '.'), 208),\n",
       " (('.', 'u'), 208),\n",
       " (('/', 'm'), 206),\n",
       " (('m', 'n'), 206),\n",
       " (('9', \"'\"), 205),\n",
       " (('x', 's'), 205),\n",
       " (('u', 'o'), 205),\n",
       " (('1', '2'), 204),\n",
       " (('/', 'b'), 204),\n",
       " (('k', 'p'), 203),\n",
       " (('/', 'o'), 202),\n",
       " (('d', 'c'), 199),\n",
       " (('r', 'h'), 196),\n",
       " (('/', 'l'), 195),\n",
       " (('-', 'h'), 194),\n",
       " (('y', 'u'), 194),\n",
       " (('3', '3'), 194),\n",
       " (('p', 'f'), 188),\n",
       " (('5', 'x'), 186),\n",
       " (('k', '.'), 185),\n",
       " (('w', 'b'), 185),\n",
       " (('0', '1'), 183),\n",
       " (('/', 'p'), 182),\n",
       " (('-', 'n'), 182),\n",
       " (('z', 'o'), 180),\n",
       " (('0', 'h'), 180),\n",
       " (('l', 'w'), 179),\n",
       " (('8', '-'), 179),\n",
       " (('w', '.'), 177),\n",
       " (('-', 'g'), 175),\n",
       " (('.', 'f'), 174),\n",
       " (('o', 'z'), 172),\n",
       " (('f', 's'), 172),\n",
       " (('.', 'd'), 172),\n",
       " (('1', '5'), 169),\n",
       " (('1', '-'), 169),\n",
       " (('.', 'p'), 168),\n",
       " (('/', 'f'), 168),\n",
       " (('n', 'z'), 168),\n",
       " (('8', 'l'), 167),\n",
       " (('y', 'w'), 164),\n",
       " (('0', 'k'), 163),\n",
       " (('p', '.'), 162),\n",
       " (('i', '.'), 161),\n",
       " (('k', '3'), 160),\n",
       " (('l', '4'), 160),\n",
       " (('9', '0'), 158),\n",
       " (('h', '.'), 157),\n",
       " (('g', '/'), 153),\n",
       " (('o', '.'), 152),\n",
       " (('2', 's'), 152),\n",
       " (('.', 'l'), 151),\n",
       " (('/', 'e'), 149),\n",
       " (('/', 'i'), 147),\n",
       " (('a', 'e'), 145),\n",
       " (('k', 'w'), 143),\n",
       " (('x', 'd'), 142),\n",
       " (('0', 't'), 141),\n",
       " (('/', 'd'), 140),\n",
       " (('x', 'l'), 140),\n",
       " (('l', 'r'), 138),\n",
       " (('0', 's'), 138),\n",
       " (('2', 't'), 135),\n",
       " (('/', 'w'), 134),\n",
       " (('6', '3'), 134),\n",
       " (('0', '6'), 134),\n",
       " ((\"'\", '”'), 133),\n",
       " (('”', \"'\"), 133),\n",
       " (('n', '\\\\'), 133),\n",
       " (('/', 'n'), 132),\n",
       " (('v', 'g'), 132),\n",
       " (('d', 'w'), 132),\n",
       " (('z', 'l'), 131),\n",
       " ((\"'\", '8'), 130),\n",
       " (('=', \"'\"), 129),\n",
       " (('g', '2'), 129),\n",
       " (('s', 'd'), 128),\n",
       " (('x', 'o'), 128),\n",
       " (('b', 'z'), 128),\n",
       " (('-', 'y'), 127),\n",
       " (('m', '/'), 126),\n",
       " (('h', 'm'), 125),\n",
       " (('z', 'd'), 125),\n",
       " (('h', 'd'), 125),\n",
       " (('i', 'i'), 124),\n",
       " (('1', '8'), 123),\n",
       " ((\"'\", '\\\\'), 122),\n",
       " ((\"'\", '“'), 121),\n",
       " (('“', \"'\"), 121),\n",
       " (('o', '/'), 121),\n",
       " (('.', 'r'), 121),\n",
       " (('1', '7'), 121),\n",
       " (('t', '\"'), 120),\n",
       " (('1', '9'), 120),\n",
       " (('r', '3'), 120),\n",
       " (('d', 't'), 119),\n",
       " (('b', '-'), 119),\n",
       " (('x', 'm'), 119),\n",
       " (('k', '/'), 118),\n",
       " ((\"'\", '~'), 117),\n",
       " (('0', '4'), 117),\n",
       " (('4', 't'), 116),\n",
       " (('l', '/'), 113),\n",
       " (('-', 'v'), 113),\n",
       " (('a', '.'), 112),\n",
       " (('s', '8'), 110),\n",
       " (('-', '7'), 110),\n",
       " (('l', 'g'), 110),\n",
       " ((\"'\", '='), 109),\n",
       " (('f', 'w'), 109),\n",
       " (('0', '3'), 109),\n",
       " (('/', 'g'), 108),\n",
       " (('b', 'v'), 107),\n",
       " (('2', '2'), 107),\n",
       " (('u', 'k'), 107),\n",
       " (('7', 'x'), 105),\n",
       " (('2', '1'), 105),\n",
       " (('9', '9'), 103),\n",
       " (('9', '\"'), 102),\n",
       " (('m', 't'), 99),\n",
       " (('q', '3'), 97),\n",
       " (('p', '/'), 97),\n",
       " (('o', '2'), 97),\n",
       " (('9', '-'), 97),\n",
       " (('0', '5'), 97),\n",
       " (('k', '5'), 97),\n",
       " (('b', 'j'), 96),\n",
       " (('.', 'y'), 96),\n",
       " (('t', '\\\\'), 95),\n",
       " (('6', '\"'), 95),\n",
       " (('1', '6'), 95),\n",
       " (('5', '\"'), 94),\n",
       " (('[', ']'), 94),\n",
       " (('4', '\"'), 94),\n",
       " (('2', 'n'), 94),\n",
       " (('3', '9'), 93),\n",
       " (('j', \"'\"), 93),\n",
       " (('n', 'w'), 93),\n",
       " (('6', '5'), 92),\n",
       " (('0', '2'), 92),\n",
       " (('8', '\"'), 92),\n",
       " (('0', '7'), 92),\n",
       " (('m', '6'), 92),\n",
       " (('5', 't'), 91),\n",
       " (('v', 'r'), 91),\n",
       " (('7', '\"'), 91),\n",
       " (('d', 'p'), 89),\n",
       " (('h', 'h'), 88),\n",
       " (('m', 'c'), 87),\n",
       " (('c', '6'), 86),\n",
       " ((']', \"'\"), 86),\n",
       " (('2', '6'), 84),\n",
       " (('i', '\\\\'), 83),\n",
       " (('0', '.'), 82),\n",
       " (('5', 's'), 82),\n",
       " (('.', '2'), 81),\n",
       " (('s', 'x'), 80),\n",
       " ((\"'\", '>'), 80),\n",
       " (('>', \"'\"), 80),\n",
       " (('j', 'x'), 80),\n",
       " (('v', '/'), 79),\n",
       " ((\"'\", '['), 79),\n",
       " (('l', '6'), 79),\n",
       " (('7', '5'), 78),\n",
       " (('/', '2'), 77),\n",
       " (('.', '-'), 77),\n",
       " (('/', 'v'), 76),\n",
       " (('v', '.'), 75),\n",
       " (('-', '0'), 74),\n",
       " (('.', 'v'), 74),\n",
       " (('v', 'v'), 74),\n",
       " (('3', '6'), 74),\n",
       " (('2', '7'), 73),\n",
       " (('-', '9'), 73),\n",
       " (('k', 'd'), 73),\n",
       " (('y', 'g'), 73),\n",
       " (('-', 'k'), 73),\n",
       " (('3', '\"'), 73),\n",
       " (('_', '_'), 73),\n",
       " (('4', 'm'), 72),\n",
       " (('w', 'k'), 71),\n",
       " (('1', '4'), 71),\n",
       " (('v', '1'), 71),\n",
       " (('0', '8'), 71),\n",
       " (('1', '1'), 71),\n",
       " (('t', 'g'), 71),\n",
       " (('0', '9'), 70),\n",
       " (('9', '3'), 69),\n",
       " (('2', '\"'), 69),\n",
       " ((',', '0'), 69),\n",
       " (('9', '4'), 68),\n",
       " (('h', 'v'), 68),\n",
       " (('3', 's'), 67),\n",
       " (('a', 'o'), 67),\n",
       " (('9', '6'), 67),\n",
       " (('b', 'w'), 67),\n",
       " (('i', 'y'), 67),\n",
       " (('p', 'c'), 66),\n",
       " (('.', '1'), 66),\n",
       " (('i', '/'), 66),\n",
       " (('k', 't'), 66),\n",
       " (('5', 'm'), 66),\n",
       " (('c', '9'), 65),\n",
       " (('u', 'u'), 65),\n",
       " (('5', 'k'), 65),\n",
       " (('u', '.'), 65),\n",
       " (('9', '8'), 65),\n",
       " (('k', 'r'), 64),\n",
       " (('b', '/'), 64),\n",
       " (('w', 'w'), 64),\n",
       " (('7', 's'), 64),\n",
       " (('0', 'm'), 63),\n",
       " (('h', '/'), 62),\n",
       " (('e', '6'), 61),\n",
       " (('b', 'c'), 61),\n",
       " (('p', '3'), 60),\n",
       " (('b', '.'), 59),\n",
       " (('x', '2'), 59),\n",
       " (('+', '+'), 59),\n",
       " (('k', '2'), 59),\n",
       " (('v', '4'), 58),\n",
       " ((\"'\", '<'), 58),\n",
       " (('<', \"'\"), 58),\n",
       " (('4', 's'), 57),\n",
       " (('f', '.'), 56),\n",
       " (('c', '/'), 56),\n",
       " (('1', 's'), 56),\n",
       " (('/', '1'), 56),\n",
       " (('f', 'm'), 55),\n",
       " (('2', 'v'), 55),\n",
       " (('x', '.'), 55),\n",
       " (('d', '\"'), 55),\n",
       " (('d', 'f'), 55),\n",
       " (('q', '6'), 55),\n",
       " (('t', 'v'), 54),\n",
       " (('1', '3'), 54),\n",
       " (('a', '+'), 53),\n",
       " (('c', 'q'), 53),\n",
       " (('z', '-'), 53),\n",
       " (('o', 'j'), 53),\n",
       " (('j', 'i'), 52),\n",
       " (('g', '5'), 52),\n",
       " (('r', '8'), 51),\n",
       " (('x', '8'), 51),\n",
       " (('.', '5'), 50),\n",
       " (('a', '7'), 50),\n",
       " (('~', \"'\"), 50),\n",
       " (('2', '9'), 50),\n",
       " (('\"', 'n'), 50),\n",
       " (('0', 'i'), 49),\n",
       " (('t', 'z'), 48),\n",
       " (('0', '\"'), 48),\n",
       " (('1', '\"'), 47),\n",
       " (('x', 'j'), 47),\n",
       " (('s', 'v'), 47),\n",
       " (('b', 'n'), 46),\n",
       " (('2', 'm'), 46),\n",
       " (('n', '\"'), 46),\n",
       " (('u', 'h'), 46),\n",
       " (('4', '2'), 46),\n",
       " (('9', '7'), 45),\n",
       " (('/', 'u'), 45),\n",
       " (('.', '3'), 44),\n",
       " (('r', '\"'), 44),\n",
       " (('m', 'k'), 44),\n",
       " (('w', 't'), 44),\n",
       " (('a', '2'), 44),\n",
       " (('–', \"'\"), 43),\n",
       " (('.', '4'), 43),\n",
       " (('k', 'b'), 43),\n",
       " (('9', '5'), 43),\n",
       " (('w', '3'), 43),\n",
       " ((\"'\", '–'), 42),\n",
       " (('.', 'j'), 42),\n",
       " (('z', 'm'), 42),\n",
       " (('s', '7'), 42),\n",
       " (('m', '2'), 42),\n",
       " (('k', 'f'), 41),\n",
       " (('f', '1'), 40),\n",
       " (('e', '9'), 40),\n",
       " (('t', 'x'), 40),\n",
       " (('x', 'x'), 39),\n",
       " (('-', 'q'), 39),\n",
       " (('b', 'd'), 39),\n",
       " (('z', '8'), 39),\n",
       " (('5', '.'), 38),\n",
       " (('t', '2'), 38),\n",
       " (('u', '-'), 38),\n",
       " (('/', '/'), 38),\n",
       " (('c', '7'), 37),\n",
       " (('n', 'q'), 37),\n",
       " (('.', '0'), 37),\n",
       " (('6', 'm'), 37),\n",
       " (('y', 'f'), 36),\n",
       " (('r', '2'), 36),\n",
       " (('y', '\"'), 36),\n",
       " (('x', 'f'), 36),\n",
       " (('w', 'm'), 36),\n",
       " (('0', ','), 36),\n",
       " (('5', '2'), 36),\n",
       " (('x', 'k'), 36),\n",
       " (('p', '2'), 36),\n",
       " (('t', '+'), 35),\n",
       " (('w', '2'), 35),\n",
       " (('q', 't'), 34),\n",
       " (('p', 'w'), 34),\n",
       " (('0', '/'), 34),\n",
       " (('h', 'k'), 34),\n",
       " (('/', 'q'), 33),\n",
       " (('d', 'h'), 33),\n",
       " (('5', 'i'), 33),\n",
       " (('5', '4'), 33),\n",
       " (('/', '3'), 33),\n",
       " (('0', 'c'), 33),\n",
       " (('q', '-'), 32),\n",
       " ((':', '1'), 32),\n",
       " (('p', 'n'), 32),\n",
       " (('r', '\\\\'), 32),\n",
       " (('3', '.'), 32),\n",
       " (('3', '4'), 32),\n",
       " (('6', 's'), 32),\n",
       " (('e', '\\\\'), 32),\n",
       " (('l', '\"'), 31),\n",
       " (('4', '.'), 31),\n",
       " (('3', '1'), 31),\n",
       " (('-', 'x'), 31),\n",
       " (('z', '0'), 31),\n",
       " (('0', 'l'), 31),\n",
       " (('\"', 'c'), 30),\n",
       " (('/', '4'), 30),\n",
       " (('3', '8'), 30),\n",
       " (('i', 'w'), 30),\n",
       " (('h', 'f'), 30),\n",
       " (('f', '/'), 30),\n",
       " (('v', 'q'), 30),\n",
       " (('i', 'h'), 29),\n",
       " (('1', '/'), 29),\n",
       " (('x', '7'), 29),\n",
       " (('5', '7'), 29),\n",
       " (('b', 'h'), 28),\n",
       " (('/', 'y'), 28),\n",
       " (('/', '5'), 28),\n",
       " (('8', '5'), 28),\n",
       " (('c', '5'), 28),\n",
       " (('c', 'x'), 27),\n",
       " (('g', '\"'), 27),\n",
       " (('\"', 'd'), 27),\n",
       " (('-', 'j'), 27),\n",
       " (('f', 'g'), 27),\n",
       " ((\"'\", '‘'), 27),\n",
       " (('‘', \"'\"), 27),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' These lines show exact frequencies for bigrams.'''\n",
    "bigram_fd = nltk.FreqDist(nltk.bigrams(big_array))\n",
    "bigram_fd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b52a9-bfda-40f2-841e-beeceaf25071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have extracted tuples inside tuples ( there are two tuples inside this tuple )\n",
    "out = [item for t in bigram_fd.most_common() for item in t] \n",
    "\n",
    "lst_tup=[] #this contains bigrams in a tuple form\n",
    "lst_num=[] #this contains the frequency of bigrams\n",
    "for i in tqdm(out):\n",
    "    j=out.index(i)\n",
    "    if j%2==0:\n",
    "        lst_tup.append(out[j])\n",
    "    else:\n",
    "        lst_num.append(out[j])\n",
    "\n",
    "# print(lst1)\n",
    "# print(lst_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110f4e5-aceb-4b4b-bec8-62321ad4b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have extracted tuples inside the first tuple using the above method\n",
    "lst_final = [] # this will contain the bigram in a 'X_Y' format\n",
    "lst_std = [item for t in lst_tup for item in t]\n",
    "for i in tqdm(lst_std):\n",
    "  j=lst_std.index(i)\n",
    "  if j%2==0:\n",
    "    t=lst_std[j]+'_' + lst_std[j+1]\n",
    "    lst_final.append(t)\n",
    "\n",
    "#print(lst_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c11034-4c7c-43cb-aa88-190dabc0a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm_wth_freq = []\n",
    "\n",
    "for i in tqdm(range(len(lst_final))):\n",
    "  if lst_num[i] >= 3:\n",
    "    l = [lst_final[i]] * lst_num[i]\n",
    "    bgm_wth_freq.extend(l)\n",
    "  else:\n",
    "    break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4ba46-01df-4ea0-bce9-3aeeef21997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(bgm_wth_freq)\n",
    "lng_sent45 =[ i for i in bgm_wth_freq ]\n",
    "docs = lng_sent45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb52ff-f781-4437-a604-d0e27524a1bf",
   "metadata": {},
   "source": [
    "# topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b988d7-86c4-4262-a726-4c9405d0ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "a = array(docs)\n",
    "print (a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10760db-da45-4c6f-b9be-708f6c10e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177046e-efa3-4d09-9850-d8a64bdd3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f04da-e005-4255-85ff-195ffa6ed720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in tqdm(range(len(docs))):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80d353-41e7-4b50-a0be-e6acc89cd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21bd298-6c79-448a-89d8-abd1810de4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fdc8c0-b028-4089-93b4-c95fa6e3e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93365e30-03bd-43c7-b138-3464122ad8ce",
   "metadata": {},
   "source": [
    "# Train LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd32a0-d616-41c7-b1c7-581fd5fbac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 5\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha=0.1,\n",
    "    eta= 0.001,\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every,\n",
    "    random_state = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d5784c-293f-49dc-9979-3fa47760fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics to display\n",
    "num_topics = 5\n",
    "\n",
    "# Number of words per topic\n",
    "num_words = 10\n",
    "\n",
    "# Print topics in the desired format\n",
    "for topic_id, topic in model.show_topics(num_topics=num_topics, num_words=num_words, formatted=True):\n",
    "    print(f\"({topic_id},\")\n",
    "    print(f\"  '{topic}')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab33bf7-5aaf-4f92-a0c1-e4ef7ffb7fc2",
   "metadata": {},
   "source": [
    "# Coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3340c0a-d1b2-470b-8ba2-6fce130daeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics \n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146ba98-3da0-4401-a321-d2ba86586065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "coherence_model_lda = CoherenceModel(model= model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76d9f5-fac3-47f8-b9a7-fa12adb95bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using UMass\n",
    "coherence_model_lda = CoherenceModel(model= model, texts=docs, dictionary=dictionary, coherence=\"u_mass\")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84340631-73fe-4bdc-b2c8-d17c00625cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c95776e-93f0-478e-8735-eb6e20dc3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=docs, start=22, limit=35, step=1)\n",
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=35; start=22; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb312d1-df7a-4aea-8bcb-62fdf98b5830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
